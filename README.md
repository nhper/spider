# spider
## 1.ip代理池的基本封装
```
实现了一个简单的ip代理池的构建(爬取的是青花代理的免费ip),通过在http://www.httpbin.org/ip验证ip的可用性，
根据返回页面的数据判断ip是否可用，可用就存入数据库，并定义一个类属性阈值来空值数据库中的ip最大数量。
check_allip()方法，可用于检查数据库中所有ip的可用性，不可用则从数据库删除

## 2.商标网爬虫
```
本项目通过使用scrapy对中国商标网进行数据爬取，由于商标网的反扒措施做的超级完善，所以想从查询页面一步步爬取商标数据几乎是不可能的(很难)
但是商标网首页右上角的商标公告里面无任何反扒措施,所以我们可以从这里入手，得到的数据是相同的。

## 3.网易云音乐评论的爬取
### 方法一:get接口 wwy_get.py
```
这个接口也是无意中发现，本来一直在破解js加密，没想到无意中发现了网易云音乐的评论有一个get接口，所以很容易从中获得到音乐评论数据
http://music.163.com/api/v1/resource/comments/R_SO_4_歌曲id?offset=页码

### 方法二:使用selenium无界面浏览区   wwy_selenium.py
```
注意一点，无界面浏览器每次只是返回的当前页面窗口的数据，而音乐评论可能在当前窗口下面，所以我们可以使用driver.switch_to.frame方法进行定位

### 方法三:破解js  wwy_crypto.py
```
也是参考的许多大神的方法和代码,需要下载Crypto加密模块,然后将js加密的方法用python模拟即可

### fenci.py
```
对爬取的评论进行一个词频统计，并显示成词云图片，需要下载jieba模块，和wordcloud模块

## 链家+电影天堂
```
使用scrapy的方法，分别对链家的房屋数据，以及电影天堂的电影信息和下载地址进行爬取，存储在mongo中
 
 ## 人人网
 ```
 爬取人人网用户的个人信息
 没有用爬虫框架
 1.通过携带cookie值保持登录状态
 2.用深度优先的思想进行爬取，爬取一个人的信息后，通过当前用户的最近访问和好友找到其他人的id,从而进行深度优先爬取
 3.爬取过程发现访问100人就会出现验证码，所以通过打码平台的接口来解决验证码问题
 
